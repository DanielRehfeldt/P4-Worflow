

# Einführung

## Rasch-Modellierung
Bei vielen Tests geht es um die Frage, ob eine Testperson eine bestimmte Fähigkeit besitzt und damit eine Aufgabe richtig lösen kann. Diese Fähigkeit, die man messen möchte, ist aber meist nicht direkt zugänglich. Man spricht auch von einer latenten Fähigkeit. Der Zugang zu dieser Fähigkeit kann also nur über Aufgaben oder Fragen erfolgen, die die Testperson beantwortet und in deren Beantwortung sich die latente Fähigkeit zeigt. 

Die Wahrscheinlichkeit, dass eine Person eine Aufgabe richtig lösen kann, hängt sowohl von der Fähigkeit der Person als auch von der Schwierigkeit der Aufgabe ab. Eine Aufgabe, die sehr oft richtig gelöst wird, könnte z.B. sehr einfach sein. Die Probanden könnten aber auch alle eine sehr hohe Fähigkeit haben, die ihnen erlaubt, die Aufgabe erfolgreich zu bearbeiten. Beide Punkte sind also auf den ersten Blick nicht voneinander zu trennen. Die Rasch-Modellierung (benannt nach dem dänischen Statistiker Georg Rasch (1901–1980)) löst dieses Problem. Das Rasch-Modell beschreibt wie wahrscheinlich es ist, dass ein Proband $n$ ein Item $i$ richtig löst in Abhängigkeit

* eines individuellen Personen- oder **Personenfähigkeitsparameters $\theta_n$** für jede Person, welche das Fähigkeitsausmaß der Person $n$ beschreibt und
* eines Aufgaben- oder **Aufgabenschwierigkeitsparameters $\delta_i$**, der den Schwierigkeitsgrad der Aufgabe $i$ beschreibt.

Man erhält also aus einem Datensatz von richtigen oder falschen Antworten (ordinale Daten) der Personen zu verschiedenen Aufgaben ein kontinuierliches intervallskaliertes Maß in Form der Personenfähigkeitsparameter $\theta_n$ und der Aufgabenschwierigkeitsparameter $\delta_i$. Prinzipiell ist dieses Modell nicht auf dichotom zu bewertende Aufgaben beschränkt. Auch likert-skalierte Items sind z.B. möglich, sollen aber nicht Gegenstand dieses Beitrages sein.

Die Modellannahmen lauten wie folgt:

* Das Maß der Fähigkeit jedes Probanden ist **ausschließlich** durch den Personenfähigkeitsparameter charakterisiert. Das heißt, dass es keine anderen Einflussfaktoren auf Seiten der Person gibt und ein sog. eindimensionales Modell berechnet wird.

* Die Schwierigkeit der einzelnen Aufgaben ist **ausschließlich** durch den Aufgabenschwierigkeitsparameter charakterisiert. Die Schwierigkeit stellt also ebenfalls ein eindimensionales Merkmal dar.

* Beide Parameter werden auf derselben Skala gemessen.

* Die Leistungen einer Person hängt über alle Aufgaben hinweg – abgesehen von Zufall –, einzig von der Fähigkeit des Probanden und der Schwierigkeit der Aufgabe ab, nicht aber davon, welche anderen Aufgaben er oder sie bereits gelöst hat oder noch lösen wird. 

Wie modelliert das Rasch-Modell nun aber genau das Antwortverhalten?

Der Zusammenhang zwischen der Lösungswahrscheinlichkeit einer Aufgabe, deren Schwierigkeit und der Fähigkeit der Person sollte jeden Fall derart sein, dass die Wahrscheinlichkeit einer richtigen Antwort mit wachsender Fähigkeit steigt. Im Idealfall könnte man annehmen, dass die Wahrscheinlichkeit einer richtigen Antwort für Personen mit einer niedrigen Fähigkeit bei null liegt und ab einer bestimmten Fähigkeit sprunghaft auf eins ansteigt. Ganz so ideal wird es aber nicht sein und der Übergangsbereich wird etwas weicher verlaufen. Explizit wird angenommen, dass sich die Wahrscheinlichkeit einer richtigen Antwort einer logistischen Funktion folgend entwickelt. Man setzt für die Wahrscheinlichkeit einer richtigen Antwort (mit 1 codiert) unter der Bedingung einer Personenfähigkeit $\theta_n$ und Schwierigkeit der Aufgabe $\delta_i$ an:

$$P(1|\theta_n, \delta_i) = \frac{\exp(\theta_n - \delta_i)}{1+\exp(\theta_n - \delta_i)} $$
Für eine Aufgabe mit dem Schwierigkeitsparameter 0 erhält man so folgenden Verlauf der Lösungswahrscheinlichkeit über den Fähigkeitsparameter.
<img src="c1_files/figure-html/modell-1.png" width="672" />
Personen mit einem Fähigkeitsparameter von -5.0 lösen diese Aufgabe also mit einer Wahrscheinlichkeit von etwa 0 (also wahrscheinlich nie), während Personen mit einem Fähigkeitsparameter von +5.0 die Aufgabe mit einer Wahrscheinlichkeit von etwa 1 (also wohl immer) lösen. Personen, deren Fähigkeitsparameter gerade so groß ist wie der Parameter der Aufgabenschwierigkeit, lösen die Aufgabe mit einer Wahrscheinlichkeit von 0.5 (also in etwa 50% der Fälle).

Im folgenden Plot ist die Lösungswahrscheinlichkeit einer Aufgabe in Abhängigkeit der Personenfähigkeit aufgetragen. Die Schwierigkeit der Aufgabe kann über den Schieberegler verändert werden. So kann z.B. verfolgt werden, wie sich die Lösungswahrscheinlichkeit einer Person mit Fähigkeitsparameter 0 ändert, wenn die Aufgabenschwierigkeit variiert wird.

<iframe src="https://moehrke.shinyapps.io/Modellfunktion/?showcase=0" width="672" height="510px"></iframe>


Personen mit einem Personenfähigkeitsparameter von 0 würden also eine Aufgabe mit $\delta = -0.5$ mit einer Wahrscheinlichkeit von 0.6 lösen, während sie eine Aufgabe mit $\delta = 1.7$ nur mit einer Wahrscheinlichkeit von 0.15 lösen würde.

Schaut man sich die Formel für die Lösungswahrscheinlichkeit noch einmal an, sieht man, dass die Lösungswahrscheinlichkeit für Aufgabe $i$ einzig von der Differenz der Parameter für Personenfähigkeit und Aufgabengabenschwierigkeit abhängt. Formt man die Gleichung etwas um, kann man auch schreiben
$$\ln\left(\frac{P(1|\theta_n, \delta_i)}{1 - P(1|\theta_n, \delta_i)}\right) = \ln\left(\frac{P(1|\theta_n, \delta_i)}{ P(0|\theta_n, \delta_i)}\right) = \theta_n - \delta_i$$

Der natürliche Logarithmus der Chance (Wahrscheinlichkeit der richtigen Lösung geteilt durch Wahrscheinlichkeit der falschen Lösung) ist gleich der Differenz von Personenfähigkeits- und Aufgabenschwierigkeitsparameter. Plottet man die Chance gegen diese Differenz erhält man eine Gerade mit Steigung 1.

Diese Steigung und damit die Steigung des Übergangs von $P$ wird für das Rasch-Modell also als fest angenommen. Die Steigung wird auch als Trennschärfe bezeichnet, weil Sie eine Aussage darüber liefert, wie klar ein Item zwischen den Fähigkeiten zweier Personen trennen kann.

Bei höheren Modellen wie dem 2-PL geht die Steigung als zusätzlicher Parameter ein.

### Beispiel
Stellt man sich für ein Beispiel vor, dass die Kochkompetenz von Probanden gemessen werden soll. Dies stellt eine latente Fähigkeit dar, die nur über Testaufgaben auf diesem Gebiet erforscht werden kann. Ein entsprechender Test sollte aus verschieden schweren Aufgaben bestehen, wie etwa

1. Zubereiten einer Tütensuppe (einfach) 
2. Kochen einer Tomatensoße nach Rezept (mittel)
3. Kochen von Milchreis (mittel)
4. Zubereitung eines mehrgängigen Menüs ohne Rezept für 4 Personen (schwer)

Welche Aufgabenschwierigkeitsparameter man diesen drei Aufgaben zuweisen würden, wie schwierig die Aufgaben also in Relation zueinander sind, ist nicht bekannt. Ob zum Beispiel Aufgabe 2 oder 3 schwieriger ist, ist schwer zu beurteilen. In realen Studien kann das bei der Erstellung der Aufgaben noch schwieriger sein.

Lässt man nun eine Zahl von Probanden alle vier Aufgaben in beliebiger Reihenfolge bearbeiten und vermerkt Erfolg (Ergebnis genießbar) oder Misserfolg (nicht genießbar), so erhält man eine Liste mit den Ergebnissen der Personen als Zeilen und den Aufgaben als Spalten. Diese Form wird auch als tidy Data (aufgeräumte/ordentliche Daten) bezeichnet und ist die bevorzugte Form, in der Daten vorliegen sollten [@wickham2014] oder * [Tidy data](https://tidyr.tidyverse.org/articles/tidy-data.html).

Mit diesen Daten kann eine Rasch Analyse gemacht werden, mit welcher man ein intervallskaliertes Maß für sowohl die Kochfähigkeit jedes einzelnen Probanden erhält (die Personenfähigkeitsparameter $\theta_n$) als auch für die Schwierigkeit der einzelnen Aufgaben (die Aufgabenschwierigkeitsparameter $\delta_i$) erhält.

### Wie wird der beste Fit gefunden?
Der beste Fit zwischen Modell und Daten, also der Satz von $\theta_n$ und $\delta_i$, der die beste Passung zwischen Modell und Daten liefert, kann über verschiedene Verfahren wie unter anderem das Least-quares- oder aber das Maximum-Likelihood-Verfahren gefunden werden [@linacre1999]. 

Bei letzterem wird durch ein iteratives Vorgehen, die sog. Likelihood-Funktion
$$ L_n= \prod\limits_{i}P(1/0|\theta_n, \delta_i)$$
für jede Personen $n$ berechnet. Diese wird genau für den Personenfähigkeitsparameter maximal, für den die Wahrscheinlichkeit maximal wird, genau dieses Antwortverhalten auf die einzelnen Items zu erhalten. Es werden also die $\theta_n$ gesucht, für die die $L_n$ maximal werden.

Die Berechnung startet mit einer Schätzung der Itemschwierigkeit über den Anteil der Personen, die eine Aufgabe richtig bearbeitet haben
$$ \delta_i = \log\left(\frac{p}{1-p}\right) $$
und sucht den Satz von Personenfähigkeitsparametern $\theta_n$, für den die Likelihood-Funktion maximal wird. Im nächsten Schritt wird mit diesen Satz von Personenfähigkeitsparametern $\theta_n$, die Likelihood-Funktion bezüglich der Itemschwierigkeitsparameter $\delta_i$ maximiert. So wird die Likelihood-Funktion immer weiter abwechseln bezüglich der $\theta_n$ und der $\delta_i$ maximiert. Dieser Vorgang sollte nach einer Zahl von Schritten konvergieren - sprich die Änderung der $\theta_n$ und $\delta_i$ wird immer kleiner und unterschreitet irgendwann einen festgelegten Wert. Dann wird der Prozess abgebrochen. 

Für einen Test mit zwei Items mit den Schwierigkeitsparametern ($\delta_1 = -1$, $\delta_1 = 0.5$) wäre die Likelihood-Funktion eines Probanden mit einer richtigen Antwort im ersten Item und einer falschen im zweiten Item:

$$L(\theta) = P(1|\theta, \delta_1 = -1) \cdot P(0|\theta, \delta_2 = 0.5)\\
  = \left(\frac{\exp(\theta + 1)}{1+\exp(\theta + 1)}\right)\cdot\left(1-\frac{\exp(\theta - 0.5)}{1+\exp(\theta - 0.5)}\right)$$
  
Für diese muss nun das Maximum bezüglich $\theta$ gefunden werden.

An dieser Stelle gibt es verschiedene Schätzmethoden für die Itemschwierigkeits- und Personenfähigkeitsparameter wie die Joint-Maximum-Likelihood-Schätzung (JML) und die Weighted Likelihood Schätzung (WLE), welche ein Bias in der Schätzung mit JML verringert. Die genauen Details dieser verschiedenen Verfahren sollen an dieser Stelle aber nicht weiter behandelt werden.

### zum Weiterlesen
Sehr interessante Videos zu diesem Thema, die das Ganze noch einmal wesentlich umfangreicher beschreiben, sind:

* [A Conceptual Introduction to Item Response Theory](https://www.youtube.com/watch?v=SrdbllMYq8M&list=PLJNUIJnElUzDmrIPunMyF3tTvIHb65wNb)
* [Logistic Regression](https://www.youtube.com/watch?v=yIYKR4sgzI8&list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe)

## Der Datensatz
Der für diese Erklärung verwendete Datensatz stammt aus dem Paket TAM und hat das Format einer einfachen Matrix. Es handelt sich um simulierte Daten von 2000 Personen (als Zeilen) zu jeweils 40 Items (als Spalten). Die Spalten für die einzelnen Items sind mit I1 bis I40 bezeichnet. Eine Spalte für eine Personen-ID oder ähnliches gibt es nicht. Auch hat der Datensatz keine fehlenden Daten, d.h. zu jedem Probanden gibt es Daten zu jedem Item. Die Items selbst sind alle dichotom (richtig/falsch) und mit 1 und 0 codiert. 


```r
data(data.sim.rasch)
head(data.sim.rasch)
```

```
##      I1 I2 I3 I4 I5 I6 I7 I8 I9 I10 I11 I12 I13 I14 I15 I16 I17 I18 I19 I20 I21
## [1,]  1  1  1  1  1  1  0  1  0   1   1   0   0   1   1   1   1   1   1   1   0
## [2,]  0  1  0  0  0  1  1  1  0   1   1   1   1   1   0   0   1   0   1   0   0
## [3,]  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   1   1   1
## [4,]  1  0  1  1  0  1  1  1  0   0   1   1   1   0   0   1   1   0   0   0   0
## [5,]  1  1  1  1  1  1  1  1  0   0   1   1   1   1   1   0   0   1   1   1   1
## [6,]  1  1  1  0  0  1  0  0  0   0   0   0   0   0   0   1   1   1   0   0   0
##      I22 I23 I24 I25 I26 I27 I28 I29 I30 I31 I32 I33 I34 I35 I36 I37 I38 I39
## [1,]   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## [2,]   0   0   1   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0
## [3,]   1   1   1   1   1   1   1   1   1   1   1   0   0   1   1   1   0   1
## [4,]   0   1   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0
## [5,]   0   1   1   1   1   1   0   1   0   0   0   1   1   1   0   1   0   0
## [6,]   1   0   0   1   0   1   1   0   0   0   1   0   0   0   0   0   0   0
##      I40
## [1,]   0
## [2,]   0
## [3,]   1
## [4,]   0
## [5,]   0
## [6,]   0
```
